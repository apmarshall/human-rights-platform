## A Sample Policy Skeleton:

**Disclaimer** This is just a thought experiment about what a company privacy/content moderation policy which followed the Universal Declaration of Human Rights based approach might look like. While I think some stuff in here will be pretty non-controversial, I am well aware that some of the items below are judgment calls that reflect my own personal perspective on how to interpret/implement an item in the Declaration. The point is to start a conversation, not propose a final resolution.

This assumes that a company is already following/implementing those things in the [sample legal framework](sample-legal-framework.md). The items below are additional things a company might consider implementing in their own content and privacy policies that are in keeping with the human rights framework.

## Violent Content
- Companies/Platforms may ban any content which showcases or encourages real violence, including content containing or supporting:
  - Threats and violent intimidation
  - Terrorism or organizations engaged in terrorism
  - Genocide/ethnic cleansing
  - Racial, religious, or sexual violence

## Human Trafficking
- Most companies/platforms should ban pornography if they are unable to verify that such content was produced with full consent of the participants and without any sort of coercion or deception.

## Content Moderation
- Companies/Platforms may take steps to encourage users to avoid posting personally derogatory content. Though they cannot be expected to police all user content, they can implement tools that will (a) warn users that their content may be out of keeping with acceptable-use policies and (b) limit the reach and impact of duly flagged content. 
- Known purveyors of fake/fabricated political news should be banned or significantly limited in their distribution.

## Child Protection and the Rights of Parents
- Advertisements which explicitly target minors may be manually reviewed.
- Accounts associated with minors may be required to have contact information for a verified adult linked to them. The verified adult's information could be used for account reset attempts and could be informed of suspicious activity within the child's account.
- Verified adult contacts could be given the option to monitor corresponding minor children’s activity on any platform, including reviewing the content they are posting, the advertisements they are seeing, and the “meta-data” of any personal correspondences they are having.
