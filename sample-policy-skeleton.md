## A Sample Policy Skeleton:

**Disclaimer** This is just a thought experiment about what a policy framework which followed the Universal Declaration of Human Rights based approach might look like. While I think some stuff in here will be pretty non-controversial, I am well aware that some of the items below are judgment calls that reflect my own personal perspective on how to interpret/implement an item in the Declaration. The point is to start a conversation, not propose a final resolution.

- Tech Companies/Platforms should generally not consent to or participate in any action which would restrict their users rights with regards to the freedoms outlined in section one of the framework except where such rights might conflict with the rights of others as outlined below.
- Companies/Platforms which directly provide or indirectly facilitate any service related to transportation or residence should (a) never engage in any sort of discriminatory practices with regards to the provision of their services (ie, housing discrimination) and (b) not tolerate discriminatory practices on the part of providers/employers who utilize their platform. 
- Companies/Platforms who employ individuals through the use of their own property (ie, drivers, home rentals, or workers using their own computers/devices) should not place any requirements on the modification, condition, or use of their property which are not strictly necessary for either (a) the provision of the service or (b) the health and safety of customers.
- Companies/Platforms which directly sell or indirectly facilitate any service-for-hire should (a) never engage in any sort of wage discrimination and (b) not tolerate wage discrimination of the part of employers who might use their platforms to hire service providers. 
- Companies/Platforms which facilitate service-for-hire work should (a) treat their core service providers as employees and (b) recognize the rights of those employees to unionize and collectively bargain.
- Companies/Platforms should ban any content which showcases or encourages real violence, including content containing or supporting:
  - Threats and violent intimidation
  - Terrorism or organizations engaged in terrorism
  - Genocide/ethnic cleansing
  - Racial, religious, or sexual violence
- Companies/Platforms which provide services-for-hire should ensure that the providers they employ meet the minimum requirements for safety and training as those in equivalent industries. Providers who engage in violent or abusive behavior should be disciplined appropriately. Any criminal activity by a provider should be reported to law enforcement and the platform should cooperate completely with any resulting investigation.
- Companies/Platforms should ban any content which pertains to human trafficking. For most platforms, this should also include a ban on pornography if the platform is unable to verify that such content was produced with full consent of the participants and without any sort of coercion or deception.
- Companies/Platforms which provide services-for-hire should ensure that their providers are fully cognizant of their rights as employees and have in no way been coerced into providing their services.
- Companies/Platforms should respect and protect the personal data of their users. Though data collected on users may have economic value to platforms, particularly those which rely on advertising, they should take care which information they monetize. In particular, they should never monetize and should take especial care to protect information pertaining to:
  - health records or data pertaining to health matters, 
  - financial, tax, or credit history records,
  - information pertaining to an individuals legal/criminal history,
  - Information about the details of a person’s family (such as the names and ages of their children), home (such as their address or phone number), or sexual activities,
  - Information posted or sent with a reasonable expectation of privacy, such as direct correspondence (email, texts, or direct/internal messages, for example), 
  - Information that, in a user's home country or present location, might be the basis for discrimination or persecution (for example, LGBTQ status for an individual located in a country with anti-LGBTQ laws).
- Best practices should be followed to protect all such private data, including the use of encryption and access limitations for staff
- Companies/Platforms may be required to produce some information in relation to legal processes. Beyond such obligations, highly personal information should never be shared with outside parties without explicit user consent for each instance of sharing.
- Users should have the right to review, modify, and remove collected data about themselves in a company's records.
- Companies/Platforms should take steps to encourage users to avoid posting personally derogatory content. Though they cannot be expected to police all user content, they can implement tools that will (a) warn users that their content may be out of keeping with acceptable-use policies and (b) limit the reach and impact of duly flagged content. Additionally, they should take direct action to remove content which has been adjudicated to be slanderous/libelous by an official court proceeding.
- “Recommendation Engines”, whether for “friend”/“follower” connections or for additional content, should be transparent and modifiable by the end user. In other words, users should be able to see why content/associations are being recommended to them and choose to “opt-out” of future recommendations based on such an association. This should be prominently and clearly displayed so that users are encouraged to take advantage of this feature.
- Users should be allowed to limit the ability of others to “follow” or “friend” them, including by limiting the search criteria/methods by which they can be found, making their profiles “private” or “restricted” for public viewing, or explicitly blocking certain individuals from following them.
- Companies/Platforms must ensure that any content (paid or organic) published by them or their users pertaining to an election (whether directly about a candidate or about a political issue) is published in “good faith.” This means:
  - Paid content must only be published by individuals verified as legal residents of the jurisdictions in which the election is taking place (ie, no outside actors paying for content)
  - All content must clearly state who produced it, who posted it, and who paid for its amplification (if applicable). Additionally, companies/platforms should make available tools which allow others to view what paid content is being promoted and how it is being targeted by other actors in the political space.
  - Demonstrably false information intended to suppress voter participation (for example, promoting the wrong day for an election or false information about voter ID requirements) should be removed and violating accounts banned from additional posting.
  - Companies/Platforms should observe a “black-out” period on political advertising prior to elections.
  - Known purveyors of fake/fabricated political news should be banned or significantly limited in their distribution.
- Companies/Platforms should strictly ban all child pornography.
- Companies/Platforms should place strict limitations about advertising targeting minors, including limitations on the types of products/services and the nature of the content used to target minors.
- Advertisements which explicitly target minors should be manually reviewed.
- Companies/Platforms which provide services-for-hire should take extra precautions around service providers who may have contact with minors and hold them to strict standards of behavior.
- Companies/Platforms should require parental consent for minors to sign-up for their service. This consent needs to be verifiable (ie, not just a check-box).
- Parents should be given the option to monitor their minor children’s activity on any platform, including reviewing the content they are posting, the advertisements they are seeing, and the “meta-data” of any personal correspondences they are having.
- Companies/Platforms should have clear, verifiable take-down procedures for content reported to be in violation of an individual’s intellectual property rights. This includes violations of a person's right to their own likeness and image: companies/platforms must respect the right of individuals to have their image and likeness permanently removed regardless of whether the requestor posted the content or it was posted by a third party.
